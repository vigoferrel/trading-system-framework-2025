#!/usr/bin/env python3
"""
BACKEND REAL QBTC - STACK UNIFICADO
Backend que conecta con servicios reales del sistema QBTC.
"""

import asyncio
import aiohttp
import json
import sqlite3
import time
import logging
from datetime import datetime

# CONFIGURACI√ìN DE LOGGING
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backend_real.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# SERVICIOS REALES
SERVICES = {
    "qbtc_core": "http://localhost:4602",
    "srona_api": "http://localhost:4601", 
    "frontend_api": "http://localhost:4603",
    "vigo_futures": "http://localhost:8002"
}

# ENDPOINTS CR√çTICOS
ENDPOINTS = [
    {"service": "qbtc_core", "name": "health", "url": "/health"},
    {"service": "qbtc_core", "name": "spot_data", "url": "/api/spot-data"},
    {"service": "qbtc_core", "name": "futures_data", "url": "/api/futures-data"},
    {"service": "qbtc_core", "name": "quantum_metrics", "url": "/api/quantum-metrics"},
    {"service": "qbtc_core", "name": "opportunities", "url": "/api/opportunities"},
    {"service": "srona_api", "name": "options_data", "url": "/api/options-data"},
    {"service": "srona_api", "name": "neural_context", "url": "/api/neural-context"},
    {"service": "frontend_api", "name": "status", "url": "/api/status"}
]

class BackendReal:
    def __init__(self, db_path="backend_real.db"):
        self.db_path = db_path
        self.session = None
        self.is_running = False
        self.start_time = None
        self.data_cache = {}
        self.metrics = {"captured": 0, "errors": 0, "healthy_services": 0}
        
        self.init_db()
        logger.info("[START] BACKEND REAL QBTC - INICIANDO")
        
    def init_db(self):
        """Inicializa la base de datos."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS real_data (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                service TEXT NOT NULL,
                endpoint TEXT NOT NULL,
                data_json TEXT NOT NULL,
                timestamp DATETIME NOT NULL,
                success BOOLEAN NOT NULL,
                response_time REAL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        logger.info("[OK] Base de datos inicializada")
    
    async def start(self):
        """Inicia el backend real."""
        self.is_running = True
        self.start_time = datetime.now()
        
        timeout = aiohttp.ClientTimeout(total=30)
        self.session = aiohttp.ClientSession(timeout=timeout)
        
        try:
            await self.run_system()
        except KeyboardInterrupt:
            logger.info("üõë Detenci√≥n solicitada")
        finally:
            await self.cleanup()
    
    async def run_system(self):
        """Ejecuta el sistema con servicios reales."""
        logger.info("[RELOAD] Iniciando sistema con servicios reales...")
        
        while self.is_running:
            start_cycle = time.time()
            
            try:
                # Verificar salud de servicios
                await self.check_services_health()
                
                # Capturar datos de todos los endpoints
                await self.capture_all_data()
                
                # Mostrar estad√≠sticas
                cycle_time = time.time() - start_cycle
                self.show_stats(cycle_time)
                
            except Exception as e:
                logger.error(f"[ERROR] Error en ciclo: {e}")
                self.metrics["errors"] += 1
            
            await asyncio.sleep(30)
    
    async def check_services_health(self):
        """Verifica la salud de los servicios."""
        logger.info("üè• Verificando servicios...")
        
        health_tasks = []
        for service_name, service_url in SERVICES.items():
            health_tasks.append(self.check_service(service_name, f"{service_url}/health"))
        
        results = await asyncio.gather(*health_tasks, return_exceptions=True)
        
        healthy_count = 0
        for i, result in enumerate(results):
            service_name = list(SERVICES.keys())[i]
            if isinstance(result, Exception):
                logger.error(f"[ERROR] {service_name}: {result}")
            else:
                healthy_count += 1
                logger.info(f"[OK] {service_name}: OK")
        
        self.metrics["healthy_services"] = healthy_count
    
    async def check_service(self, service_name: str, url: str):
        """Verifica un servicio espec√≠fico."""
        try:
            async with self.session.get(url, timeout=5) as response:
                if response.status == 200:
                    return True
                else:
                    raise Exception(f"HTTP {response.status}")
        except Exception as e:
            raise Exception(f"Error: {e}")
    
    async def capture_all_data(self):
        """Captura datos de todos los endpoints."""
        logger.info("[DATA] Capturando datos reales...")
        
        capture_tasks = []
        for endpoint in ENDPOINTS:
            service_url = SERVICES[endpoint["service"]]
            full_url = f"{service_url}{endpoint['url']}"
            capture_tasks.append(self.capture_endpoint(endpoint["service"], endpoint["name"], full_url))
        
        results = await asyncio.gather(*capture_tasks, return_exceptions=True)
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                logger.warning(f"[WARNING] Error capturando {ENDPOINTS[i]['service']}/{ENDPOINTS[i]['name']}: {result}")
            else:
                self.metrics["captured"] += 1
    
    async def capture_endpoint(self, service: str, endpoint: str, url: str):
        """Captura datos de un endpoint espec√≠fico."""
        start_time = time.time()
        
        try:
            async with self.session.get(url, timeout=10) as response:
                response_time = time.time() - start_time
                
                if response.status == 200:
                    data = await response.json()
                    
                    # Almacenar en cach√©
                    cache_key = f"{service}_{endpoint}"
                    self.data_cache[cache_key] = {
                        "data": data,
                        "timestamp": datetime.now(),
                        "response_time": response_time
                    }
                    
                    # Almacenar en base de datos
                    await self.store_data(service, endpoint, data, True, response_time)
                    
                    logger.info(f"[OK] {service}/{endpoint}: Datos capturados ({response_time:.2f}s)")
                    return True
                else:
                    raise Exception(f"HTTP {response.status}")
                    
        except Exception as e:
            await self.store_data(service, endpoint, {"error": str(e)}, False, 0)
            raise e
    
    async def store_data(self, service: str, endpoint: str, data: dict, success: bool, response_time: float):
        """Almacena datos en la base de datos."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO real_data (service, endpoint, data_json, timestamp, success, response_time)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                service,
                endpoint,
                json.dumps(data),
                datetime.now().isoformat(),
                success,
                response_time
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"[ERROR] Error almacenando datos: {e}")
    
    def show_stats(self, cycle_time: float):
        """Muestra estad√≠sticas del sistema."""
        if self.start_time:
            uptime = datetime.now() - self.start_time
            uptime_str = str(uptime).split('.')[0]
            
            logger.info("=" * 50)
            logger.info(f"[DATA] ESTAD√çSTICAS BACKEND REAL")
            logger.info(f"‚è±Ô∏è  Uptime: {uptime_str}")
            logger.info(f"[UP] Datos capturados: {self.metrics['captured']}")
            logger.info(f"[ERROR] Errores: {self.metrics['errors']}")
            logger.info(f"üè• Servicios saludables: {self.metrics['healthy_services']}/{len(SERVICES)}")
            logger.info(f"[RELOAD] Ciclo: {cycle_time:.2f}s")
            logger.info(f"[DATA] Datos en cach√©: {len(self.data_cache)} endpoints")
            logger.info("=" * 50)
    
    async def cleanup(self):
        """Limpia recursos."""
        logger.info("üßπ Limpiando recursos...")
        
        if self.session:
            await self.session.close()
        
        self.is_running = False
        logger.info("[OK] Backend real detenido")

async def main():
    """Funci√≥n principal."""
    print("=" * 60)
    print("[START] BACKEND REAL QBTC - STACK UNIFICADO")
    print("=" * 60)
    print("[DATA] Conectando a servicios reales del sistema")
    print("üîó QBTC Core - SRONA API - Frontend - Vigo Futures")
    print("[ENDPOINTS] Sin simulaciones - Solo datos reales")
    print("=" * 60)
    
    backend = BackendReal()
    
    try:
        await backend.start()
    except KeyboardInterrupt:
        print("\nüõë Detenci√≥n solicitada por el usuario")
    except Exception as e:
        print(f"\n[ERROR] Error fatal: {e}")

if __name__ == "__main__":
    asyncio.run(main())
