#!/usr/bin/env python3
"""
ORQUESTADOR DE DATOS PTIMO - SISTEMA UNIFICADO QBTC
Script orquestador en ASCII puro que automatiza la captura de datos.
"""

import asyncio
import aiohttp
import json
import sqlite3
import time
from datetime import datetime
from typing import Dict, List

# CONSTANTES FSICAS REALES
PHYSICAL_CONSTANTS = {
    "QUANTUM_COHERENCE": 0.75,
    "QUANTUM_CONSCIOUSNESS": 0.8,
    "QUANTUM_ENTANGLEMENT": 0.65,
    "QUANTUM_SUPERPOSITION": 0.7,
    "QUANTUM_TUNNELING": 0.6,
    "MARKET_VOLATILITY": 0.05,
    "MARKET_MOMENTUM": 0.1,
    "MARKET_LIQUIDITY": 0.75,
    "MARKET_SPREAD": 0.001,
    "MARKET_DEPTH": 500000,
    "FUNDING_RATE": 0.02,
    "FUNDING_VOLATILITY": 0.01,
    "FUNDING_DEVIATION": 0.5,
    "FUNDING_ANNUALIZED": 5,
    "LIQUIDATION_PROBABILITY": 0.05,
    "SLIPPAGE_RATE": 0.0025,
    "VOLATILITY_RISK": 0.1,
    "EXECUTION_RISK": 0.005,
    "VOLUME_24H": 500000,
    "VOLUME_RATIO": 0.75,
    "VOLUME_EXPANSION": 300000,
    "PRICE_CHANGE": 0.02,
    "PRICE_ACCELERATION": 0.015,
    "PRICE_MOMENTUM": 0.01,
    "TIME_TO_FUNDING": 1800000,
    "SESSION_INTENSITY": 0.6,
    "TEMPORAL_RESONANCE": 0.7,
    "FIBONACCI_STRENGTH": 0.75,
    "FIBONACCI_INDEX": 5,
    "NEURAL_CONFIDENCE": 0.85,
    "NEURAL_COHERENCE": 0.8,
    "NEURAL_ENTANGLEMENT": 0.7,
    "BASE_LEVERAGE": 15,
    "CONSERVATIVE_LEVERAGE": 10,
    "AGGRESSIVE_LEVERAGE": 25,
    "STOP_LOSS": 0.03,
    "TAKE_PROFIT": 0.06,
    "BASE_SCORE": 0.65,
    "CONFIDENCE_SCORE": 0.75,
    "QUALITY_SCORE": 0.8
}

# ENDPOINTS CRTICOS
ENDPOINTS = [
    {"name": "spot_data", "url": "http://localhost:4602/api/spot-data", "freq": 30},
    {"name": "futures_data", "url": "http://localhost:4602/api/futures-data", "freq": 30},
    {"name": "quantum_metrics", "url": "http://localhost:4602/api/quantum-metrics", "freq": 45},
    {"name": "health", "url": "http://localhost:4602/health", "freq": 60},
    {"name": "options_data", "url": "http://localhost:4601/api/options-data", "freq": 60},
    {"name": "neural_context", "url": "http://localhost:4601/api/neural-context", "freq": 90},
    {"name": "frontend_status", "url": "http://localhost:4603/api/status", "freq": 120}
]

class OrquestadorDatos:
    def __init__(self, db_path="datos_optimos.db"):
        self.db_path = db_path
        self.session = None
        self.is_running = False
        self.captured_count = 0
        self.error_count = 0
        self.start_time = None
        self.last_capture = {}
        
        self.init_db()
        print("[START] ORQUESTADOR DE DATOS PTIMO - INICIANDO")
        print(f"[DATA] Base de datos: {self.db_path}")
        print(f"[ENDPOINTS] Endpoints: {len(ENDPOINTS)}")
        
    def init_db(self):
        """Inicializa la base de datos."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS captured_data (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                endpoint_name TEXT NOT NULL,
                timestamp DATETIME NOT NULL,
                data_json TEXT NOT NULL,
                success BOOLEAN NOT NULL,
                response_time REAL,
                created_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS metrics (
                endpoint_name TEXT PRIMARY KEY,
                success_count INTEGER DEFAULT 0,
                error_count INTEGER DEFAULT 0,
                avg_response_time REAL DEFAULT 0,
                last_success DATETIME,
                last_error DATETIME,
                updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        conn.commit()
        conn.close()
        print("[OK] Base de datos inicializada")
    
    async def start(self):
        """Inicia el orquestador."""
        self.is_running = True
        self.start_time = datetime.now()
        
        timeout = aiohttp.ClientTimeout(total=30)
        self.session = aiohttp.ClientSession(timeout=timeout)
        
        try:
            await self.run_capture()
        except KeyboardInterrupt:
            print(" Detenci贸n solicitada")
        finally:
            await self.cleanup()
    
    async def run_capture(self):
        """Ejecuta la captura de datos."""
        print(" Iniciando captura de datos...")
        
        while self.is_running:
            start_cycle = time.time()
            
            # Crear tareas para todos los endpoints
            tasks = []
            for endpoint in ENDPOINTS:
                if self.should_capture(endpoint):
                    tasks.append(self.capture_endpoint(endpoint))
            
            # Ejecutar tareas en paralelo
            if tasks:
                results = await asyncio.gather(*tasks, return_exceptions=True)
                
                for result in results:
                    if isinstance(result, Exception):
                        self.error_count += 1
                        print(f"[ERROR] Error: {result}")
                    else:
                        self.captured_count += 1
            
            # Mostrar estad铆sticas
            cycle_time = time.time() - start_cycle
            self.show_stats(cycle_time)
            
            # Esperar antes del siguiente ciclo
            await asyncio.sleep(10)
    
    def should_capture(self, endpoint):
        """Determina si se debe capturar datos."""
        name = endpoint["name"]
        freq = endpoint["freq"]
        
        if name not in self.last_capture:
            return True
        
        time_since = time.time() - self.last_capture[name]
        return time_since >= freq
    
    async def capture_endpoint(self, endpoint):
        """Captura datos de un endpoint espec铆fico."""
        start_time = time.time()
        
        try:
            async with self.session.get(endpoint["url"]) as response:
                if response.status == 200:
                    data = await response.json()
                    
                    # Almacenar datos
                    await self.store_data(endpoint["name"], data, True, time.time() - start_time)
                    
                    # Actualizar timestamp
                    self.last_capture[endpoint["name"]] = time.time()
                    
                    print(f"[OK] {endpoint['name']}: Datos capturados")
                    return True
                else:
                    raise Exception(f"HTTP {response.status}")
                    
        except Exception as e:
            await self.store_data(endpoint["name"], {"error": str(e)}, False, 0)
            print(f"[ERROR] {endpoint['name']}: {e}")
            return False
    
    async def store_data(self, endpoint_name, data, success, response_time):
        """Almacena datos en la base de datos."""
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        # Insertar datos capturados
        cursor.execute('''
            INSERT INTO captured_data (endpoint_name, timestamp, data_json, success, response_time)
            VALUES (?, ?, ?, ?, ?)
        ''', (
            endpoint_name,
            datetime.now().isoformat(),
            json.dumps(data),
            success,
            response_time
        ))
        
        # Actualizar m茅tricas
        if success:
            cursor.execute('''
                INSERT OR REPLACE INTO metrics 
                (endpoint_name, success_count, last_success, avg_response_time, updated_at)
                VALUES (?, 
                    COALESCE((SELECT success_count FROM metrics WHERE endpoint_name = ?), 0) + 1,
                    ?, 
                    COALESCE((SELECT avg_response_time FROM metrics WHERE endpoint_name = ?), 0) * 0.9 + ? * 0.1,
                    ?
                )
            ''', (
                endpoint_name, endpoint_name,
                datetime.now().isoformat(),
                endpoint_name, response_time,
                datetime.now().isoformat()
            ))
        else:
            cursor.execute('''
                INSERT OR REPLACE INTO metrics 
                (endpoint_name, error_count, last_error, updated_at)
                VALUES (?, 
                    COALESCE((SELECT error_count FROM metrics WHERE endpoint_name = ?), 0) + 1,
                    ?, ?
                )
            ''', (
                endpoint_name, endpoint_name,
                datetime.now().isoformat(),
                datetime.now().isoformat()
            ))
        
        conn.commit()
        conn.close()
    
    def show_stats(self, cycle_time):
        """Muestra estad铆sticas."""
        if self.start_time:
            uptime = datetime.now() - self.start_time
            uptime_str = str(uptime).split('.')[0]
            
            print("=" * 50)
            print(f"[DATA] ESTADSTICAS")
            print(f"憋  Uptime: {uptime_str}")
            print(f"[UP] Capturados: {self.captured_count}")
            print(f"[ERROR] Errores: {self.error_count}")
            print(f"[RELOAD] Ciclo: {cycle_time:.2f}s")
            print(f"[FAST] Tasa: {self.captured_count / max(uptime.total_seconds(), 1):.2f} datos/s")
            print("=" * 50)
    
    async def cleanup(self):
        """Limpia recursos."""
        print("Ч Limpiando recursos...")
        
        if self.session:
            await self.session.close()
        
        self.is_running = False
        print("[OK] Orquestador detenido")

async def main():
    """Funci贸n principal."""
    print("=" * 60)
    print("[START] ORQUESTADOR DE DATOS PTIMO - SISTEMA UNIFICADO QBTC")
    print("=" * 60)
    print("[DATA] Automatizaci贸n completa de captura de datos")
    print("锔 Backend en Python con base de datos SQLite")
    print("[ENDPOINTS] Basado en an谩lisis completo del sistema")
    print("=" * 60)
    
    orquestador = OrquestadorDatos()
    
    try:
        await orquestador.start()
    except KeyboardInterrupt:
        print("\n Detenci贸n solicitada por el usuario")
    except Exception as e:
        print(f"\n[ERROR] Error fatal: {e}")

if __name__ == "__main__":
    asyncio.run(main())
