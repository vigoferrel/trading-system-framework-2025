#!/usr/bin/env python3
"""
BACKEND UNIFICADO QBTC - STACK REAL
Backend que integra todos los servicios reales del sistema QBTC sin simulaciones.
"""

import asyncio
import aiohttp
import json
import sqlite3
import time
import logging
from datetime import datetime
from typing import Dict, List, Any

# CONFIGURACI√ìN DE LOGGING
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backend_unificado_real.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# SERVICIOS REALES DEL STACK QBTC
SERVICES = {
    "qbtc_core": {
        "url": "http://localhost:4602",
        "endpoints": {
            "health": "/health",
            "spot_data": "/api/spot-data",
            "futures_data": "/api/futures-data",
            "quantum_metrics": "/api/quantum-metrics",
            "opportunities": "/api/opportunities",
            "market_health": "/api/market-health"
        }
    },
    "srona_api": {
        "url": "http://localhost:4601",
        "endpoints": {
            "options_data": "/api/options-data",
            "neural_context": "/api/neural-context",
            "quantum_factors": "/api/quantum-factors",
            "leonardo_feynman": "/api/leonardo-feynman"
        }
    },
    "frontend_api": {
        "url": "http://localhost:4603",
        "endpoints": {
            "status": "/api/status",
            "quantum_metrics": "/api/quantum-metrics",
            "opportunities_data": "/api/opportunities-data"
        }
    },
    "vigo_futures": {
        "url": "http://localhost:8002",
        "endpoints": {
            "status": "/api/status",
            "balance": "/api/balance",
            "positions": "/api/positions"
        }
    }
}

class BackendUnificadoReal:
    def __init__(self, db_path="backend_unificado_real.db"):
        self.db_path = db_path
        self.session = None
        self.is_running = False
        self.start_time = None
        
        # Cach√© de datos reales
        self.data_cache = {
            "market_data": {},
            "quantum_metrics": {},
            "neural_data": {},
            "opportunities": {},
            "system_status": {}
        }
        
        # M√©tricas del sistema
        self.metrics = {
            "data_captured": 0,
            "errors": 0,
            "services_healthy": 0,
            "last_update": None
        }
        
        self.init_database()
        logger.info("[START] BACKEND UNIFICADO QBTC - STACK REAL")
        logger.info("[DATA] Conectando a servicios reales del sistema")
        
    def init_database(self):
        """Inicializa la base de datos para datos reales."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Tabla de datos unificados
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS unified_data (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    service_name TEXT NOT NULL,
                    endpoint_name TEXT NOT NULL,
                    data_json TEXT NOT NULL,
                    timestamp DATETIME NOT NULL,
                    success BOOLEAN NOT NULL,
                    response_time REAL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Tabla de estado de servicios
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS service_status (
                    service_name TEXT PRIMARY KEY,
                    is_healthy BOOLEAN NOT NULL,
                    last_check DATETIME NOT NULL,
                    response_time REAL,
                    error_count INTEGER DEFAULT 0,
                    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Tabla de oportunidades consolidadas
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS consolidated_opportunities (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    strategy TEXT NOT NULL,
                    confidence REAL NOT NULL,
                    source TEXT NOT NULL,
                    data_json TEXT NOT NULL,
                    timestamp DATETIME NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            conn.commit()
            conn.close()
            logger.info("[OK] Base de datos inicializada para datos reales")
            
        except Exception as e:
            logger.error(f"[ERROR] Error inicializando base de datos: {e}")
            raise
    
    async def start(self):
        """Inicia el backend unificado con stack real."""
        self.is_running = True
        self.start_time = datetime.now()
        
        # Configuraci√≥n de sesi√≥n HTTP
        timeout = aiohttp.ClientTimeout(total=30)
        connector = aiohttp.TCPConnector(
            limit=100,
            limit_per_host=30,
            ttl_dns_cache=300,
            use_dns_cache=True,
            keepalive_timeout=30
        )
        
        self.session = aiohttp.ClientSession(
            timeout=timeout,
            connector=connector,
            headers={'User-Agent': 'QBTC-Backend-Unified-Real/1.0'}
        )
        
        try:
            await self.run_unified_system()
        except KeyboardInterrupt:
            logger.info("üõë Detenci√≥n solicitada")
        except Exception as e:
            logger.error(f"[ERROR] Error en el backend: {e}")
        finally:
            await self.cleanup()
    
    async def run_unified_system(self):
        """Ejecuta el sistema unificado con servicios reales."""
        logger.info("[RELOAD] Iniciando sistema unificado con stack real...")
        
        while self.is_running:
            start_cycle = time.time()
            
            try:
                # 1. Verificar salud de todos los servicios
                await self.check_services_health()
                
                # 2. Capturar datos de QBTC Core
                await self.capture_qbtc_data()
                
                # 3. Capturar datos de SRONA API
                await self.capture_srona_data()
                
                # 4. Capturar datos de Frontend API
                await self.capture_frontend_data()
                
                # 5. Capturar datos de Vigo Futures
                await self.capture_vigo_futures_data()
                
                # 6. Consolidar oportunidades
                await self.consolidate_opportunities()
                
                # 7. Actualizar m√©tricas
                self.update_metrics()
                
                # 8. Mostrar estad√≠sticas
                cycle_time = time.time() - start_cycle
                self.show_system_stats(cycle_time)
                
            except Exception as e:
                logger.error(f"[ERROR] Error en ciclo del sistema: {e}")
                self.metrics["errors"] += 1
            
            # Esperar antes del siguiente ciclo
            await asyncio.sleep(30)
    
    async def check_services_health(self):
        """Verifica la salud de todos los servicios."""
        logger.info("üè• Verificando salud de servicios...")
        
        health_tasks = []
        for service_name, service_config in SERVICES.items():
            health_url = f"{service_config['url']}/health"
            health_tasks.append(self.check_service_health(service_name, health_url))
        
        results = await asyncio.gather(*health_tasks, return_exceptions=True)
        
        healthy_count = 0
        for i, result in enumerate(results):
            service_name = list(SERVICES.keys())[i]
            if isinstance(result, Exception):
                logger.error(f"[ERROR] {service_name}: {result}")
                await self.update_service_status(service_name, False, 0)
            else:
                healthy_count += 1
                logger.info(f"[OK] {service_name}: Saludable")
                await self.update_service_status(service_name, True, result)
        
        self.metrics["services_healthy"] = healthy_count
    
    async def check_service_health(self, service_name: str, health_url: str):
        """Verifica la salud de un servicio espec√≠fico."""
        start_time = time.time()
        
        try:
            async with self.session.get(health_url, timeout=5) as response:
                response_time = time.time() - start_time
                
                if response.status == 200:
                    return response_time
                else:
                    raise Exception(f"HTTP {response.status}")
                    
        except Exception as e:
            raise Exception(f"Error de conectividad: {e}")
    
    async def capture_qbtc_data(self):
        """Captura datos del QBTC Core."""
        logger.info("[DATA] Capturando datos de QBTC Core...")
        
        service_config = SERVICES["qbtc_core"]
        
        # Capturar datos de spot
        await self.capture_endpoint_data("qbtc_core", "spot_data", 
                                       f"{service_config['url']}{service_config['endpoints']['spot_data']}")
        
        # Capturar datos de futures
        await self.capture_endpoint_data("qbtc_core", "futures_data", 
                                       f"{service_config['url']}{service_config['endpoints']['futures_data']}")
        
        # Capturar m√©tricas cu√°nticas
        await self.capture_endpoint_data("qbtc_core", "quantum_metrics", 
                                       f"{service_config['url']}{service_config['endpoints']['quantum_metrics']}")
        
        # Capturar oportunidades
        await self.capture_endpoint_data("qbtc_core", "opportunities", 
                                       f"{service_config['url']}{service_config['endpoints']['opportunities']}")
    
    async def capture_srona_data(self):
        """Captura datos de SRONA API."""
        logger.info("üß† Capturando datos de SRONA API...")
        
        service_config = SERVICES["srona_api"]
        
        # Capturar datos de opciones
        await self.capture_endpoint_data("srona_api", "options_data", 
                                       f"{service_config['url']}{service_config['endpoints']['options_data']}")
        
        # Capturar contexto neural
        await self.capture_endpoint_data("srona_api", "neural_context", 
                                       f"{service_config['url']}{service_config['endpoints']['neural_context']}")
        
        # Capturar factores cu√°nticos
        await self.capture_endpoint_data("srona_api", "quantum_factors", 
                                       f"{service_config['url']}{service_config['endpoints']['quantum_factors']}")
    
    async def capture_frontend_data(self):
        """Captura datos del Frontend API."""
        logger.info("üñ•Ô∏è Capturando datos de Frontend API...")
        
        service_config = SERVICES["frontend_api"]
        
        # Capturar estado del frontend
        await self.capture_endpoint_data("frontend_api", "status", 
                                       f"{service_config['url']}{service_config['endpoints']['status']}")
        
        # Capturar m√©tricas cu√°nticas del frontend
        await self.capture_endpoint_data("frontend_api", "quantum_metrics", 
                                       f"{service_config['url']}{service_config['endpoints']['quantum_metrics']}")
    
    async def capture_vigo_futures_data(self):
        """Captura datos de Vigo Futures."""
        logger.info("[UP] Capturando datos de Vigo Futures...")
        
        service_config = SERVICES["vigo_futures"]
        
        # Capturar estado de Vigo Futures
        await self.capture_endpoint_data("vigo_futures", "status", 
                                       f"{service_config['url']}{service_config['endpoints']['status']}")
        
        # Capturar balance
        await self.capture_endpoint_data("vigo_futures", "balance", 
                                       f"{service_config['url']}{service_config['endpoints']['balance']}")
    
    async def capture_endpoint_data(self, service_name: str, endpoint_name: str, url: str):
        """Captura datos de un endpoint espec√≠fico."""
        start_time = time.time()
        
        try:
            async with self.session.get(url, timeout=10) as response:
                response_time = time.time() - start_time
                
                if response.status == 200:
                    data = await response.json()
                    
                    # Almacenar en cach√©
                    cache_key = f"{service_name}_{endpoint_name}"
                    self.data_cache["market_data"][cache_key] = {
                        "data": data,
                        "timestamp": datetime.now(),
                        "response_time": response_time
                    }
                    
                    # Almacenar en base de datos
                    await self.store_unified_data(service_name, endpoint_name, data, True, response_time)
                    
                    self.metrics["data_captured"] += 1
                    logger.debug(f"[OK] {service_name}/{endpoint_name}: Datos capturados ({response_time:.2f}s)")
                    
                else:
                    raise Exception(f"HTTP {response.status}")
                    
        except Exception as e:
            await self.store_unified_data(service_name, endpoint_name, {"error": str(e)}, False, 0)
            logger.warning(f"[WARNING] {service_name}/{endpoint_name}: {e}")
    
    async def consolidate_opportunities(self):
        """Consolida oportunidades de todos los servicios."""
        logger.info("[ENDPOINTS] Consolidando oportunidades...")
        
        # Buscar oportunidades en QBTC Core
        qbtc_opportunities = self.data_cache["market_data"].get("qbtc_core_opportunities", {}).get("data", {})
        
        # Buscar oportunidades en SRONA
        srona_opportunities = self.data_cache["market_data"].get("srona_api_options_data", {}).get("data", {})
        
        # Consolidar oportunidades
        consolidated = []
        
        # Procesar oportunidades de QBTC
        if "opportunities" in qbtc_opportunities:
            for opp in qbtc_opportunities["opportunities"]:
                consolidated.append({
                    "symbol": opp.get("symbol", "UNKNOWN"),
                    "strategy": opp.get("strategy", "UNKNOWN"),
                    "confidence": opp.get("confidence", 0.5),
                    "source": "QBTC_CORE",
                    "data": opp
                })
        
        # Procesar oportunidades de SRONA
        if "opportunities" in srona_opportunities:
            for opp in srona_opportunities["opportunities"]:
                consolidated.append({
                    "symbol": opp.get("symbol", "UNKNOWN"),
                    "strategy": opp.get("strategy", "UNKNOWN"),
                    "confidence": opp.get("confidence", 0.5),
                    "source": "SRONA_API",
                    "data": opp
                })
        
        # Almacenar oportunidades consolidadas
        for opp in consolidated:
            await self.store_consolidated_opportunity(opp)
        
        self.data_cache["opportunities"] = consolidated
        logger.info(f"[DATA] {len(consolidated)} oportunidades consolidadas")
    
    async def store_unified_data(self, service_name: str, endpoint_name: str, data: Dict, success: bool, response_time: float):
        """Almacena datos unificados en la base de datos."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO unified_data (service_name, endpoint_name, data_json, timestamp, success, response_time)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                service_name,
                endpoint_name,
                json.dumps(data),
                datetime.now().isoformat(),
                success,
                response_time
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"[ERROR] Error almacenando datos unificados: {e}")
    
    async def update_service_status(self, service_name: str, is_healthy: bool, response_time: float):
        """Actualiza el estado de un servicio."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            error_count = 0 if is_healthy else 1
            
            cursor.execute('''
                INSERT OR REPLACE INTO service_status 
                (service_name, is_healthy, last_check, response_time, error_count, updated_at)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                service_name,
                is_healthy,
                datetime.now().isoformat(),
                response_time,
                error_count,
                datetime.now().isoformat()
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"[ERROR] Error actualizando estado de servicio: {e}")
    
    async def store_consolidated_opportunity(self, opportunity: Dict):
        """Almacena oportunidad consolidada."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO consolidated_opportunities (symbol, strategy, confidence, source, data_json, timestamp)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                opportunity["symbol"],
                opportunity["strategy"],
                opportunity["confidence"],
                opportunity["source"],
                json.dumps(opportunity["data"]),
                datetime.now().isoformat()
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"[ERROR] Error almacenando oportunidad consolidada: {e}")
    
    def update_metrics(self):
        """Actualiza m√©tricas del sistema."""
        self.metrics["last_update"] = datetime.now()
    
    def show_system_stats(self, cycle_time: float):
        """Muestra estad√≠sticas del sistema."""
        if self.start_time:
            uptime = datetime.now() - self.start_time
            uptime_str = str(uptime).split('.')[0]
            
            logger.info("=" * 60)
            logger.info(f"[DATA] ESTAD√çSTICAS DEL SISTEMA UNIFICADO REAL")
            logger.info(f"‚è±Ô∏è  Uptime: {uptime_str}")
            logger.info(f"[UP] Datos capturados: {self.metrics['data_captured']}")
            logger.info(f"[ERROR] Errores: {self.metrics['errors']}")
            logger.info(f"üè• Servicios saludables: {self.metrics['services_healthy']}/{len(SERVICES)}")
            logger.info(f"[RELOAD] Ciclo: {cycle_time:.2f}s")
            logger.info(f"[DATA] Datos en cach√©: {len(self.data_cache['market_data'])} endpoints")
            logger.info(f"[ENDPOINTS] Oportunidades: {len(self.data_cache.get('opportunities', []))}")
            logger.info("=" * 60)
    
    async def cleanup(self):
        """Limpia recursos."""
        logger.info("üßπ Limpiando recursos...")
        
        if self.session:
            await self.session.close()
        
        self.is_running = False
        logger.info("[OK] Backend unificado real detenido")

async def main():
    """Funci√≥n principal."""
    print("=" * 70)
    print("[START] BACKEND UNIFICADO QBTC - STACK REAL")
    print("=" * 70)
    print("[DATA] Integraci√≥n de servicios reales del sistema QBTC")
    print("üîó QBTC Core (4602) - SRONA API (4601) - Frontend (4603)")
    print("[UP] Vigo Futures (8002) - Sin simulaciones")
    print("[ENDPOINTS] Consolidaci√≥n real de oportunidades de trading")
    print("=" * 70)
    
    backend = BackendUnificadoReal()
    
    try:
        await backend.start()
    except KeyboardInterrupt:
        print("\nüõë Detenci√≥n solicitada por el usuario")
    except Exception as e:
        print(f"\n[ERROR] Error fatal: {e}")
        logger.error(f"Error fatal en el backend: {e}")

if __name__ == "__main__":
    asyncio.run(main())
