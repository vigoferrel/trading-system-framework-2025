#!/usr/bin/env python3
"""
BACKEND UNIFICADO QBTC - SISTEMA COMPLETO
Backend √∫nico que integra todas las funcionalidades del sistema de trading cu√°ntico.
"""

import asyncio
import aiohttp
import json
import sqlite3
import time
import logging
from datetime import datetime
from typing import Dict, List

# CONSTANTES F√çSICAS REALES
PHYSICAL_CONSTANTS = {
    "QUANTUM_COHERENCE": 0.75,
    "QUANTUM_CONSCIOUSNESS": 0.8,
    "QUANTUM_ENTANGLEMENT": 0.65,
    "QUANTUM_SUPERPOSITION": 0.7,
    "QUANTUM_TUNNELING": 0.6,
    "MARKET_VOLATILITY": 0.05,
    "MARKET_MOMENTUM": 0.1,
    "MARKET_LIQUIDITY": 0.75,
    "MARKET_SPREAD": 0.001,
    "MARKET_DEPTH": 500000,
    "FUNDING_RATE": 0.02,
    "FUNDING_VOLATILITY": 0.01,
    "FUNDING_DEVIATION": 0.5,
    "FUNDING_ANNUALIZED": 5,
    "LIQUIDATION_PROBABILITY": 0.05,
    "SLIPPAGE_RATE": 0.0025,
    "VOLATILITY_RISK": 0.1,
    "EXECUTION_RISK": 0.005,
    "VOLUME_24H": 500000,
    "VOLUME_RATIO": 0.75,
    "VOLUME_EXPANSION": 300000,
    "PRICE_CHANGE": 0.02,
    "PRICE_ACCELERATION": 0.015,
    "PRICE_MOMENTUM": 0.01,
    "TIME_TO_FUNDING": 1800000,
    "SESSION_INTENSITY": 0.6,
    "TEMPORAL_RESONANCE": 0.7,
    "FIBONACCI_STRENGTH": 0.75,
    "FIBONACCI_INDEX": 5,
    "NEURAL_CONFIDENCE": 0.85,
    "NEURAL_COHERENCE": 0.8,
    "NEURAL_ENTANGLEMENT": 0.7,
    "BASE_LEVERAGE": 15,
    "CONSERVATIVE_LEVERAGE": 10,
    "AGGRESSIVE_LEVERAGE": 25,
    "STOP_LOSS": 0.03,
    "TAKE_PROFIT": 0.06,
    "BASE_SCORE": 0.65,
    "CONFIDENCE_SCORE": 0.75,
    "QUALITY_SCORE": 0.8
}

# CONFIGURACI√ìN DE LOGGING
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('backend_unificado.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

class BackendUnificado:
    def __init__(self, db_path="backend_unificado.db"):
        self.db_path = db_path
        self.session = None
        self.is_running = False
        self.start_time = None
        
        # Cach√© de datos en memoria
        self.market_cache = {}
        self.quantum_cache = {}
        self.neural_cache = {}
        self.psychological_cache = {}
        
        # M√©tricas del sistema
        self.metrics = {
            "data_captured": 0,
            "errors": 0,
            "last_update": None,
            "system_health": "HEALTHY"
        }
        
        self.init_database()
        logger.info("[START] BACKEND UNIFICADO QBTC - INICIANDO")
        
    def init_database(self):
        """Inicializa la base de datos unificada."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            # Tabla de datos de mercado
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS market_data (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    price REAL NOT NULL,
                    volume REAL NOT NULL,
                    change_24h REAL NOT NULL,
                    timestamp DATETIME NOT NULL,
                    data_type TEXT NOT NULL,
                    source TEXT NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Tabla de m√©tricas cu√°nticas
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS quantum_metrics (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    coherence REAL NOT NULL,
                    consciousness REAL NOT NULL,
                    entanglement REAL NOT NULL,
                    superposition REAL NOT NULL,
                    tunneling REAL NOT NULL,
                    timestamp DATETIME NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Tabla de an√°lisis neural
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS neural_analysis (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    confidence REAL NOT NULL,
                    coherence REAL NOT NULL,
                    entanglement REAL NOT NULL,
                    prediction TEXT,
                    timestamp DATETIME NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Tabla de an√°lisis psicol√≥gico
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS psychological_analysis (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    fear_greed_index REAL NOT NULL,
                    sentiment_score REAL NOT NULL,
                    market_regime TEXT NOT NULL,
                    timestamp DATETIME NOT NULL,
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            # Tabla de oportunidades de trading
            cursor.execute('''
                CREATE TABLE IF NOT EXISTS trading_opportunities (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    symbol TEXT NOT NULL,
                    strategy TEXT NOT NULL,
                    confidence REAL NOT NULL,
                    risk_score REAL NOT NULL,
                    potential_return REAL NOT NULL,
                    timestamp DATETIME NOT NULL,
                    status TEXT DEFAULT 'ACTIVE',
                    created_at DATETIME DEFAULT CURRENT_TIMESTAMP
                )
            ''')
            
            conn.commit()
            conn.close()
            logger.info("[OK] Base de datos unificada inicializada")
            
        except Exception as e:
            logger.error(f"[ERROR] Error inicializando base de datos: {e}")
            raise
    
    async def start(self):
        """Inicia el backend unificado."""
        self.is_running = True
        self.start_time = datetime.now()
        
        # Configuraci√≥n de sesi√≥n HTTP
        timeout = aiohttp.ClientTimeout(total=30)
        connector = aiohttp.TCPConnector(
            limit=100,
            limit_per_host=30,
            ttl_dns_cache=300,
            use_dns_cache=True,
            keepalive_timeout=30
        )
        
        self.session = aiohttp.ClientSession(
            timeout=timeout,
            connector=connector,
            headers={'User-Agent': 'QBTC-Backend-Unified/1.0'}
        )
        
        try:
            await self.run_system()
        except KeyboardInterrupt:
            logger.info("üõë Detenci√≥n solicitada")
        except Exception as e:
            logger.error(f"[ERROR] Error en el backend: {e}")
        finally:
            await self.cleanup()
    
    async def run_system(self):
        """Ejecuta el sistema unificado."""
        logger.info("[RELOAD] Iniciando sistema unificado...")
        
        while self.is_running:
            start_cycle = time.time()
            
            try:
                # 1. Capturar datos de mercado
                await self.capture_market_data()
                
                # 2. Calcular m√©tricas cu√°nticas
                await self.calculate_quantum_metrics()
                
                # 3. An√°lisis neural
                await self.perform_neural_analysis()
                
                # 4. An√°lisis psicol√≥gico
                await self.perform_psychological_analysis()
                
                # 5. Generar oportunidades de trading
                await self.generate_trading_opportunities()
                
                # 6. Actualizar m√©tricas del sistema
                self.update_system_metrics()
                
                # 7. Mostrar estad√≠sticas
                cycle_time = time.time() - start_cycle
                self.show_system_stats(cycle_time)
                
            except Exception as e:
                logger.error(f"[ERROR] Error en ciclo del sistema: {e}")
                self.metrics["errors"] += 1
            
            # Esperar antes del siguiente ciclo
            await asyncio.sleep(30)
    
    async def capture_market_data(self):
        """Captura datos de mercado de m√∫ltiples fuentes."""
        logger.info("[DATA] Capturando datos de mercado...")
        
        # Simular captura de datos (en producci√≥n se conectar√≠a a APIs reales)
        symbols = ["BTCUSDT", "ETHUSDT", "BNBUSDT", "ADAUSDT", "SOLUSDT"]
        
        for symbol in symbols:
            # Generar datos simulados basados en constantes f√≠sicas
            price = 50000 + (hash(symbol) % 10000)  # Precio base + variaci√≥n
            volume = PHYSICAL_CONSTANTS["VOLUME_24H"] * (0.5 + (hash(symbol) % 100) / 100)
            change_24h = (hash(symbol) % 20 - 10) / 100  # Cambio entre -10% y +10%
            
            market_data = {
                "symbol": symbol,
                "price": price,
                "volume": volume,
                "change_24h": change_24h,
                "timestamp": datetime.now().isoformat(),
                "data_type": "spot",
                "source": "QBTC_BACKEND"
            }
            
            # Almacenar en cach√© y base de datos
            self.market_cache[symbol] = market_data
            await self.store_market_data(market_data)
            
            self.metrics["data_captured"] += 1
    
    async def calculate_quantum_metrics(self):
        """Calcula m√©tricas cu√°nticas basadas en datos de mercado."""
        logger.info("‚öõÔ∏è Calculando m√©tricas cu√°nticas...")
        
        # Calcular m√©tricas basadas en constantes f√≠sicas y datos de mercado
        coherence = PHYSICAL_CONSTANTS["QUANTUM_COHERENCE"]
        consciousness = PHYSICAL_CONSTANTS["QUANTUM_CONSCIOUSNESS"]
        entanglement = PHYSICAL_CONSTANTS["QUANTUM_ENTANGLEMENT"]
        superposition = PHYSICAL_CONSTANTS["QUANTUM_SUPERPOSITION"]
        tunneling = PHYSICAL_CONSTANTS["QUANTUM_TUNNELING"]
        
        # Ajustar basado en volatilidad del mercado
        if self.market_cache:
            avg_change = sum(abs(data["change_24h"]) for data in self.market_cache.values()) / len(self.market_cache)
            volatility_factor = min(1.0, avg_change * 10)  # Factor de volatilidad
            
            coherence *= (1 + volatility_factor * 0.1)
            consciousness *= (1 - volatility_factor * 0.05)
            entanglement *= (1 + volatility_factor * 0.15)
        
        quantum_metrics = {
            "coherence": coherence,
            "consciousness": consciousness,
            "entanglement": entanglement,
            "superposition": superposition,
            "tunneling": tunneling,
            "timestamp": datetime.now().isoformat()
        }
        
        # Almacenar m√©tricas
        self.quantum_cache = quantum_metrics
        await self.store_quantum_metrics(quantum_metrics)
    
    async def perform_neural_analysis(self):
        """Realiza an√°lisis neural de los s√≠mbolos."""
        logger.info("üß† Realizando an√°lisis neural...")
        
        for symbol, market_data in self.market_cache.items():
            # Calcular m√©tricas neurales basadas en datos de mercado
            confidence = PHYSICAL_CONSTANTS["NEURAL_CONFIDENCE"]
            coherence = PHYSICAL_CONSTANTS["NEURAL_COHERENCE"]
            entanglement = PHYSICAL_CONSTANTS["NEURAL_ENTANGLEMENT"]
            
            # Ajustar basado en volumen y cambio de precio
            volume_factor = min(1.0, market_data["volume"] / PHYSICAL_CONSTANTS["VOLUME_24H"])
            change_factor = abs(market_data["change_24h"])
            
            confidence *= (0.8 + volume_factor * 0.2)
            coherence *= (0.9 + change_factor * 0.1)
            entanglement *= (0.7 + volume_factor * 0.3)
            
            # Generar predicci√≥n
            if market_data["change_24h"] > 0.05:
                prediction = "BULLISH"
            elif market_data["change_24h"] < -0.05:
                prediction = "BEARISH"
            else:
                prediction = "NEUTRAL"
            
            # Almacenar an√°lisis neural
            await self.store_neural_analysis(symbol, confidence, coherence, entanglement, prediction)
    
    async def perform_psychological_analysis(self):
        """Realiza an√°lisis psicol√≥gico del mercado."""
        logger.info("üß† Realizando an√°lisis psicol√≥gico...")
        
        for symbol, market_data in self.market_cache.items():
            # Calcular √≠ndice de miedo y codicia
            fear_greed_index = 50  # Base neutral
            
            # Ajustar basado en volatilidad y volumen
            volatility = abs(market_data["change_24h"])
            volume_ratio = market_data["volume"] / PHYSICAL_CONSTANTS["VOLUME_24H"]
            
            if volatility > 0.1:  # Alta volatilidad
                fear_greed_index += 20
            if volume_ratio > 1.5:  # Alto volumen
                fear_greed_index += 15
            if market_data["change_24h"] < -0.05:  # Ca√≠da
                fear_greed_index -= 10
            
            # Normalizar entre 0 y 100
            fear_greed_index = max(0, min(100, fear_greed_index))
            
            # Calcular score de sentimiento
            sentiment_score = (fear_greed_index - 50) / 50  # Entre -1 y 1
            
            # Determinar r√©gimen de mercado
            if fear_greed_index > 70:
                market_regime = "GREED"
            elif fear_greed_index < 30:
                market_regime = "FEAR"
            else:
                market_regime = "NEUTRAL"
            
            # Almacenar an√°lisis psicol√≥gico
            await self.store_psychological_analysis(symbol, fear_greed_index, sentiment_score, market_regime)
    
    async def generate_trading_opportunities(self):
        """Genera oportunidades de trading basadas en todos los an√°lisis."""
        logger.info("[ENDPOINTS] Generando oportunidades de trading...")
        
        for symbol, market_data in self.market_cache.items():
            # Calcular score de confianza combinando todos los an√°lisis
            confidence = 0.5  # Base
            
            # Factor de volumen
            volume_factor = min(1.0, market_data["volume"] / PHYSICAL_CONSTANTS["VOLUME_24H"])
            confidence += volume_factor * 0.2
            
            # Factor de cambio de precio
            change_factor = abs(market_data["change_24h"])
            confidence += change_factor * 0.3
            
            # Factor cu√°ntico
            if self.quantum_cache:
                confidence += self.quantum_cache["coherence"] * 0.2
            
            # Normalizar confianza
            confidence = min(1.0, confidence)
            
            # Calcular score de riesgo
            risk_score = 1.0 - confidence
            
            # Calcular retorno potencial
            potential_return = abs(market_data["change_24h"]) * 2  # 2x el cambio actual
            
            # Determinar estrategia
            if market_data["change_24h"] > 0.05:
                strategy = "LONG"
            elif market_data["change_24h"] < -0.05:
                strategy = "SHORT"
            else:
                strategy = "HOLD"
            
            # Solo generar oportunidades con alta confianza
            if confidence > 0.7:
                await self.store_trading_opportunity(symbol, strategy, confidence, risk_score, potential_return)
    
    async def store_market_data(self, market_data: Dict):
        """Almacena datos de mercado en la base de datos."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO market_data (symbol, price, volume, change_24h, timestamp, data_type, source)
                VALUES (?, ?, ?, ?, ?, ?, ?)
            ''', (
                market_data["symbol"],
                market_data["price"],
                market_data["volume"],
                market_data["change_24h"],
                market_data["timestamp"],
                market_data["data_type"],
                market_data["source"]
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"[ERROR] Error almacenando datos de mercado: {e}")
    
    async def store_quantum_metrics(self, quantum_metrics: Dict):
        """Almacena m√©tricas cu√°nticas en la base de datos."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO quantum_metrics (coherence, consciousness, entanglement, superposition, tunneling, timestamp)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                quantum_metrics["coherence"],
                quantum_metrics["consciousness"],
                quantum_metrics["entanglement"],
                quantum_metrics["superposition"],
                quantum_metrics["tunneling"],
                quantum_metrics["timestamp"]
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"[ERROR] Error almacenando m√©tricas cu√°nticas: {e}")
    
    async def store_neural_analysis(self, symbol: str, confidence: float, coherence: float, entanglement: float, prediction: str):
        """Almacena an√°lisis neural en la base de datos."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO neural_analysis (symbol, confidence, coherence, entanglement, prediction, timestamp)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                symbol,
                confidence,
                coherence,
                entanglement,
                prediction,
                datetime.now().isoformat()
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"[ERROR] Error almacenando an√°lisis neural: {e}")
    
    async def store_psychological_analysis(self, symbol: str, fear_greed_index: float, sentiment_score: float, market_regime: str):
        """Almacena an√°lisis psicol√≥gico en la base de datos."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO psychological_analysis (symbol, fear_greed_index, sentiment_score, market_regime, timestamp)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                symbol,
                fear_greed_index,
                sentiment_score,
                market_regime,
                datetime.now().isoformat()
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"[ERROR] Error almacenando an√°lisis psicol√≥gico: {e}")
    
    async def store_trading_opportunity(self, symbol: str, strategy: str, confidence: float, risk_score: float, potential_return: float):
        """Almacena oportunidad de trading en la base de datos."""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            
            cursor.execute('''
                INSERT INTO trading_opportunities (symbol, strategy, confidence, risk_score, potential_return, timestamp)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                symbol,
                strategy,
                confidence,
                risk_score,
                potential_return,
                datetime.now().isoformat()
            ))
            
            conn.commit()
            conn.close()
            
        except Exception as e:
            logger.error(f"[ERROR] Error almacenando oportunidad de trading: {e}")
    
    def update_system_metrics(self):
        """Actualiza m√©tricas del sistema."""
        self.metrics["last_update"] = datetime.now()
        
        # Verificar salud del sistema
        if self.metrics["errors"] > 10:
            self.metrics["system_health"] = "WARNING"
        elif self.metrics["errors"] > 20:
            self.metrics["system_health"] = "CRITICAL"
        else:
            self.metrics["system_health"] = "HEALTHY"
    
    def show_system_stats(self, cycle_time: float):
        """Muestra estad√≠sticas del sistema."""
        if self.start_time:
            uptime = datetime.now() - self.start_time
            uptime_str = str(uptime).split('.')[0]
            
            logger.info("=" * 60)
            logger.info(f"[DATA] ESTAD√çSTICAS DEL SISTEMA UNIFICADO")
            logger.info(f"‚è±Ô∏è  Uptime: {uptime_str}")
            logger.info(f"[UP] Datos capturados: {self.metrics['data_captured']}")
            logger.info(f"[ERROR] Errores: {self.metrics['errors']}")
            logger.info(f"[RELOAD] Ciclo: {cycle_time:.2f}s")
            logger.info(f"üè• Salud: {self.metrics['system_health']}")
            logger.info(f"[DATA] S√≠mbolos en cach√©: {len(self.market_cache)}")
            logger.info(f"‚öõÔ∏è M√©tricas cu√°nticas: {'ACTIVAS' if self.quantum_cache else 'INACTIVAS'}")
            logger.info("=" * 60)
    
    async def cleanup(self):
        """Limpia recursos."""
        logger.info("üßπ Limpiando recursos...")
        
        if self.session:
            await self.session.close()
        
        self.is_running = False
        logger.info("[OK] Backend unificado detenido")

async def main():
    """Funci√≥n principal."""
    print("=" * 70)
    print("[START] BACKEND UNIFICADO QBTC - SISTEMA COMPLETO")
    print("=" * 70)
    print("[DATA] Sistema de trading cu√°ntico unificado")
    print("‚öõÔ∏è Integraci√≥n de datos, an√°lisis y oportunidades")
    print("üß† An√°lisis neural y psicol√≥gico integrado")
    print("[ENDPOINTS] Generaci√≥n autom√°tica de oportunidades")
    print("=" * 70)
    
    backend = BackendUnificado()
    
    try:
        await backend.start()
    except KeyboardInterrupt:
        print("\nüõë Detenci√≥n solicitada por el usuario")
    except Exception as e:
        print(f"\n[ERROR] Error fatal: {e}")
        logger.error(f"Error fatal en el backend: {e}")

if __name__ == "__main__":
    asyncio.run(main())
